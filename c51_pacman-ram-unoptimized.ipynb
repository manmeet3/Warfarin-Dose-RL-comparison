{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "odNaDE1zyrL2"
   },
   "source": [
    "##Install Rendering dependancies, takes around 45 seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8-AxnvAVyzQQ"
   },
   "outputs": [],
   "source": [
    "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8A-1LTSH88EE"
   },
   "source": [
    "## Gym Pacman Environment Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCelFzWY9MBI",
    "outputId": "a651c553-49b5-4ea6-f38e-539744be123a"
   },
   "outputs": [],
   "source": [
    "#!apt-get update > /dev/null 2>&1\n",
    "#!apt-get install cmake > /dev/null 2>&1\n",
    "#!pip install --upgrade setuptools 2>&1\n",
    "!pip install ez_setup > /dev/null 2>&1\n",
    "!pip install gym[atari] > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2i1TPuNvCI-n"
   },
   "source": [
    "## Mount G-drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9TlpMNxoAv0U",
    "outputId": "40f3b26d-c858-4e7c-9eb5-f973a0b08f71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsKuF_iOA2BO",
    "outputId": "7124491c-6aa7-4d8a-ccaa-a9b8e817fbc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/Shareddrives/RL-project/Models/C51\n"
     ]
    }
   ],
   "source": [
    "#%cd /content/drive/Shareddrives/RL-project/Models/C51/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o32ZcER9BdAe",
    "outputId": "92bb7b31-212f-40ac-d536-5e0461201de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/Shareddrives/RL-project/Models/C51\n"
     ]
    }
   ],
   "source": [
    "#!pwd\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APXSx7hg19TH"
   },
   "source": [
    "# Imports and Helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "pdb2JwZy4jGj"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "gymlogger.set_level(40) #error only\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score_logger import ScoreLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3BGbWOu179M"
   },
   "source": [
    "# Pacman!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "6R6Qzv43MZdM"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "from IPython import display as ipythondisplay\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FV9XKIJVBPM4",
    "outputId": "252d7c0e-451c-4537-c515-0a1eadfb2890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/device:GPU:0\n",
      "Sun Nov 29 08:25:34 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 106...  Off  | 00000000:2D:00.0  On |                  N/A |\r\n",
      "|  0%   50C    P0    27W / 140W |   5774MiB /  6077MiB |      1%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have GPU available to train\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8nj5sjsk15IT",
    "outputId": "3162bcec-13ac-4757-9d3d-b78dbb6bc074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_size:  128\n",
      "action size:  9\n",
      "Epsilon update:  0.9333400000000001\n",
      "Epsilon update:  0.8666800000000001\n",
      "Epsilon update:  0.8000200000000002\n",
      "Epsilon update:  0.7333600000000002\n",
      "Epsilon update:  0.6667000000000003\n",
      "Epsilon update:  0.6000400000000004\n",
      "Epsilon update:  0.5333800000000004\n",
      "Epsilon update:  0.4667200000000004\n",
      "Epsilon update:  0.4000600000000004\n",
      "Epsilon update:  0.3334000000000004\n",
      "Epsilon update:  0.2667400000000004\n",
      "Epsilon update:  0.20008000000000042\n",
      "Epsilon update:  0.13342000000000043\n",
      "Epsilon update:  0.06676000000000043\n",
      "Epsilon update:  0.00010000000000043308\n",
      "Epsilon update:  -0.06655999999999956\n",
      "episode: 0   score: 200.0   memory length: 1921   epsilon: -0.06655999999999956\n",
      "episode: 1   score: 180.0   memory length: 3818   epsilon: -0.06655999999999956\n",
      "episode: 2   score: 260.0   memory length: 5931   epsilon: -0.06655999999999956\n",
      "episode: 3   score: 170.0   memory length: 7604   epsilon: -0.06655999999999956\n",
      "episode: 4   score: 230.0   memory length: 9765   epsilon: -0.06655999999999956\n",
      "episode: 5   score: 260.0   memory length: 11814   epsilon: -0.06655999999999956\n",
      "episode: 6   score: 290.0   memory length: 13983   epsilon: -0.06655999999999956\n",
      "episode: 7   score: 100.0   memory length: 15880   epsilon: -0.06655999999999956\n",
      "episode: 8   score: 190.0   memory length: 17769   epsilon: -0.06655999999999956\n",
      "episode: 9   score: 110.0   memory length: 19322   epsilon: -0.06655999999999956\n",
      "episode: 10   score: 0.0   memory length: 21251   epsilon: -0.06655999999999956\n",
      "episode: 11   score: 0.0   memory length: 23180   epsilon: -0.06655999999999956\n",
      "episode: 12   score: 0.0   memory length: 25109   epsilon: -0.06655999999999956\n",
      "episode: 13   score: 0.0   memory length: 27038   epsilon: -0.06655999999999956\n",
      "episode: 14   score: 0.0   memory length: 28967   epsilon: -0.06655999999999956\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f292858bb42e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;31m# every time step do the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestep_per_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-f292858bb42e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;31m# and do the model fit!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     dataset = dataset.map(\n\u001b[0;32m--> 397\u001b[0;31m         grab_batch, num_parallel_calls=dataset_ops.AUTOTUNE)\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;31m# Default optimizations are disabled to avoid the overhead of (unnecessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1700\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m           preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4082\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4084\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4085\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4086\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2939\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0;31m# places (like Keras) where the FuncGraph lives longer than the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m         \u001b[0;31m# ConcreteFunction.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m         shared_func_graph=False)\n\u001b[0m\u001b[1;32m   3083\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func_graph, attrs, shared_func_graph, function_spec)\u001b[0m\n\u001b[1;32m   1540\u001b[0m     \u001b[0;31m# FuncGraph directly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m     self._delayed_rewrite_functions = _DelayedRewriteGradientFunctions(\n\u001b[0;32m-> 1542\u001b[0;31m         func_graph, self._attrs, self._garbage_collector)\n\u001b[0m\u001b[1;32m   1543\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_order_tape_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_higher_order_tape_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[1;32m    604\u001b[0m     self._inference_function = _EagerDefinedFunction(\n\u001b[1;32m    605\u001b[0m         \u001b[0m_inference_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         self._func_graph.inputs, self._func_graph.outputs, attrs)\n\u001b[0m\u001b[1;32m    607\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[1;32m    461\u001b[0m       \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0mfunction_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0mfunction_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: allow passing of hyper params as a colab form (nice UI)\n",
    "EPISODES   = 200\n",
    "load_model = False # TODO: Set up proper saving and loading of model checkpoints\n",
    "\n",
    "class C51Agent:\n",
    "    def __init__(self, state_size, action_size, num_atoms=51):\n",
    "        self.state_size = state_size \n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self. gamma = 0.99\n",
    "        self.learning_rate = 0.0001\n",
    "        self.epsilon = 1.0\n",
    "        self.initial_epsilon = 1.0\n",
    "        self.final_epsilon = 0.0001\n",
    "        self.batch_size = 32\n",
    "        self.observe = 10\n",
    "        self.explore = 15\n",
    "        self.timestep_per_train = 5\n",
    "\n",
    "        # C51 Specific Params\n",
    "        self.num_atoms = num_atoms # 51 for C51. This is # of distribution intervals\n",
    "        self.v_max = 30            # TODO: Update me\n",
    "        self.v_min = -10           # TODO: Update me\n",
    "        self.delta_z = (self.v_max - self.v_min) / float(self.num_atoms - 1) # TODO: Update me\n",
    "        self.z = [self.v_min + i * self.delta_z for i in range(self.num_atoms)] # TODO: Update me\n",
    "\n",
    "        # create main replay memory for the agent using deque\n",
    "        self.memory = deque(maxlen=50000)\n",
    "\n",
    "        # create main model\n",
    "        self.model = self.build_model(input_shape=self.state_size, num_atoms=self.num_atoms, action_size=self.action_size, learning_rate=self.learning_rate)\n",
    "\n",
    "        #Loading weights if load_model=True\n",
    "        if load_model:\n",
    "            self.model.load_weights(\"./pacman-c51.h5\")\n",
    "\n",
    "    def build_model(self, input_shape, num_atoms, action_size, learning_rate):\n",
    "        '''\n",
    "        Description: \n",
    "        Arguments: \n",
    "\n",
    "        Return: \n",
    "        '''\n",
    "        state_input = Input(shape=(input_shape))\n",
    "        dense = Dense(1024, activation='relu')(state_input)\n",
    "        dense = Dense(1024, activation='relu')(dense)\n",
    "        dense = Dense(512, activation='relu')(dense)\n",
    "        dense = Dense(256, activation='relu')(dense)\n",
    "        dense = Dense(128, activation='relu')(dense)\n",
    "\n",
    "        distribution_list = []\n",
    "        for i in range(action_size):\n",
    "            distribution_list.append(Dense(num_atoms, activation='softmax')(dense))\n",
    "\n",
    "        model = Model(inputs=state_input, outputs=distribution_list)\n",
    "        adam = Adam(lr=learning_rate)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=adam)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        Description: Exploit with epsilon probability, otherwise sample an optimal \n",
    "        distribution interval.\n",
    "\n",
    "        Arguments: \n",
    "\n",
    "        Retval: \n",
    "        '''\n",
    "        action_idx = None\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            action_idx = random.randrange(self.action_size)\n",
    "          #print(\"rand action\")\n",
    "        else:\n",
    "            action_idx = self.get_optimal_action(state)\n",
    "          #print(\"pred action\")\n",
    "        return action_idx\n",
    "        \n",
    "\n",
    "    def get_optimal_action(self, state):\n",
    "        '''\n",
    "        Description: \n",
    "\n",
    "        Arguments: \n",
    "\n",
    "        Retval: \n",
    "        '''\n",
    "        z = self.model.predict(state)\n",
    "\n",
    "        z_concat = np.vstack(z)\n",
    "        q = np.sum(np.multiply(z_concat, np.array(self.z)), axis=1)\n",
    "\n",
    "        # Pick action with biggest Q value\n",
    "        action_idx = np.argmax(q)\n",
    "\n",
    "        return action_idx\n",
    "\n",
    "    # save sample <state,action,reward,nest_state> to the replay memory\n",
    "    def add_to_memory(self, state, action, reward, next_state, done):\n",
    "        '''\n",
    "        Description: \n",
    "\n",
    "        Arguments: \n",
    "\n",
    "        Retval: \n",
    "        '''\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.final_epsilon and t > self.observe:\n",
    "            self.epsilon -= (self.initial_epsilon - self.final_epsilon) / self.explore\n",
    "            print(\"Epsilon update: \", self.epsilon)\n",
    "\n",
    "\n",
    "    def train_model(self):\n",
    "        '''\n",
    "        Description: \n",
    "\n",
    "        Arguments: \n",
    "\n",
    "        Retval: \n",
    "        '''\n",
    "        #print(\"Training Model\")\n",
    "        num_samples = min(self.batch_size * self.timestep_per_train, len(self.memory))\n",
    "        replay_samples = random.sample(self.memory, num_samples)\n",
    "\n",
    "        state_inputs = np.zeros((num_samples, self.state_size)) # ((num_samples,) + self.state_size)\n",
    "        next_states = np.zeros((num_samples, self.state_size))\n",
    "        m_prob = [np.zeros((num_samples, self.num_atoms)) for i in range(self.action_size)]\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            state_inputs[i] = replay_samples[i][0]\n",
    "            action.append(replay_samples[i][1])\n",
    "            reward.append(replay_samples[i][2])\n",
    "            next_states[i] = replay_samples[i][3]\n",
    "            done.append(replay_samples[i][4])\n",
    "        \n",
    "        # Get target state and expected value \n",
    "        z = self.model.predict(next_states)\n",
    "        z_ = self.model.predict(next_states)\n",
    "\n",
    "        # ----- C51 ----\n",
    "        # Get optimal actions for the next states (from distribution z)\n",
    "        optimal_action_idxs = []\n",
    "        z_concat = np.vstack(z)\n",
    "        q = np.sum(np.multiply(z_concat, np.array(self.z)), axis=1) # length (num_atoms * num_actions)\n",
    "        q = q.reshape((num_samples, action_size), order='F')\n",
    "        optimal_action_idxs = np.argmax(q, axis=1)\n",
    "\n",
    "        for i in range(num_samples): # TODO: should this be the local batch_size or global self.batch_size var?\n",
    "            if done[i]: # terminal state\n",
    "                # Distribution collapses to single point\n",
    "                Tz = min(self.v_max, max(self.v_min, reward[i]))\n",
    "                bj = (Tz - self.v_min) / self.delta_z\n",
    "                m_l, m_u = math.floor(bj), math.ceil(bj)\n",
    "                m_prob[action[i]][i][int(m_l)] += (m_u - bj)\n",
    "                m_prob[action[i]][i][int(m_u)] += (bj - m_l)\n",
    "                #target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                for j in range(self.num_atoms):\n",
    "                    Tz = min(self.v_max, max(self.v_min, reward[i] + self.gamma * self.z[j]))\n",
    "                    bj = (Tz - self.v_min) / self.delta_z\n",
    "                    m_l, m_u = math.floor(bj), math.ceil(bj)\n",
    "                    m_prob[action[i]][i][int(m_l)] += z_[optimal_action_idxs[i]][i][j] * (m_u - bj)\n",
    "                    m_prob[action[i]][i][int(m_u)] += z_[optimal_action_idxs[i]][i][j] * (bj - m_l)\n",
    "\n",
    "        # and do the model fit!\n",
    "        loss = self.model.fit(state_inputs, m_prob, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "        \n",
    "        return loss.history['loss']\n",
    "\n",
    "        # load the saved model\n",
    "    def load_model(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    # save the model which is under training\n",
    "    def save_model(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = gym.make('MsPacman-ramNoFrameskip-v4')\n",
    "    env.reset()\n",
    "    score_logger = ScoreLogger('MsPacman-ram-v0')\n",
    "    # get size of state and action from environment\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "    print(\"state_size: \", state_size)\n",
    "    print(\"action size: \", action_size)\n",
    "    agent = C51Agent(state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        lives = 3\n",
    "        t = 0\n",
    "        loss_tot = np.array([])\n",
    "        while not done:\n",
    "            loss = 0\n",
    "            # get action for the current state and go one step in environment\n",
    "            action = agent.get_action(state)\n",
    "            #print(action)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            dead = info['ale.lives']<lives\n",
    "            lives = info['ale.lives']\n",
    "            #print(\"Reward: \", reward)\n",
    "            #print(\"Lives: \", info['ale.lives'])\n",
    "            #print(\"Dead: \", dead)\n",
    "            #print(\"Score: \", score)\n",
    "            # When Pacman dies gives penalty of -100\n",
    "            reward = reward if not dead else -20\n",
    "            score += reward\n",
    "            \n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            # save the sample <s, a, r, s'> to the replay memory\n",
    "            agent.add_to_memory(state, action, score, next_state, done)\n",
    "            # every time step do the training\n",
    "            if t > agent.observe and t % agent.timestep_per_train == 0:\n",
    "                loss = agent.train_model()\n",
    "                loss_tot = np.append(loss_tot, loss)\n",
    "            \n",
    "            state = next_state\n",
    "            t+=1\n",
    "            \n",
    "            if done:\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                pylab.plot(episodes, scores, 'b')\n",
    "                pylab.savefig( \"pacmanTest.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                         len(agent.memory), \"  epsilon:\", agent.epsilon, \"loss: \", np.average(loss_tot))\n",
    "                #score_logger.add_score(step, run)\n",
    "     \n",
    "        if (e % 10 == 0) & (load_model==False):\n",
    "            agent.model.save_weights(\"pacman-c51-\" + str(e) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yM7eR1_mxD7s"
   },
   "outputs": [],
   "source": [
    "agent.model.save_weights(\"pacman-c51-100.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsReOmI7xFbi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "c51_with_rendering_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
